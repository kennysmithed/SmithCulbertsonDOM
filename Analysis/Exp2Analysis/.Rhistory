#labelEnteredj <- c(labelEnteredj,split.trial.as.string[6]) #label built by participant
this.score <- as.numeric(split.trial.as.string[12]) #score on this trial
}
if (grepl("NounComprehension",this.TrialBlock)) {
add.to.data <- 1
this.label <- split.trial.as.string[4] #text as appears on screen
#this.wordOrder <- word.order(this.label)
#soundj <- c(soundj,split.trial.as.string[4]) #sound file
this.meaning <- NA #image
#labelEnteredj <- c(labelEnteredj,split.trial.as.string[6]) #label built by participant
this.score <- as.numeric(split.trial.as.string[10]) #score on this trial
}
if (grepl("SentenceComprehension",this.TrialBlock)) {
add.to.data <- 1
this.label <- split.trial.as.string[7] #text as appears on screen
#this.wordOrder <- word.order(this.label)
#soundj <- c(soundj,split.trial.as.string[4]) #sound file
this.meaning <- paste(split.trial.as.string[4:6],collapse='_') #image
#labelEnteredj <- c(labelEnteredj,split.trial.as.string[6]) #label built by participant
this.score <- as.numeric(split.trial.as.string[15]) #score on this trial
}
if (grepl("SentenceTest",this.TrialBlock)) {
add.to.data <- 1
this.label <- split.trial.as.string[8] #lower-case string typed by participant
#this.wordOrder <- word.order(this.label)
#soundj <- c(soundj,split.trial.as.string[4]) #sound file
this.meaning <- paste(split.trial.as.string[4:6],collapse='_') #image
#labelEnteredj <- c(labelEnteredj,split.trial.as.string[6]) #label built by participant
this.score <- as.numeric(split.trial.as.string[9]) #score on this trial
}
if (grepl("InteractionDirect",this.TrialBlock)) {
add.to.data <- 1
this.label <- split.trial.as.string[8] #lower-case string typed by participant
#this.wordOrder <- word.order(this.label)
#soundj <- c(soundj,split.trial.as.string[4]) #sound file
this.meaning <- paste(split.trial.as.string[4:6],collapse='_') #image
#labelEnteredj <- c(labelEnteredj,split.trial.as.string[6]) #label built by participant
this.score <- as.numeric(split.trial.as.string[9]) #score on this trial
}
if (grepl("InteractionMatch",this.TrialBlock)) {
add.to.data <- 1
this.label <- split.trial.as.string[7] #lower-case string typed by participant
#this.wordOrder <- word.order(this.label)
#soundj <- c(soundj,split.trial.as.string[4]) #sound file
this.meaning <- paste(split.trial.as.string[4:6],collapse='_') #image
#labelEnteredj <- c(labelEnteredj,split.trial.as.string[6]) #label built by participant
this.score <- as.numeric(split.trial.as.string[19]) #score on this trial
}
if (add.to.data ==1) {
this.data <- data.frame("workerId"=workerIdj,
"hitid"=hitIdj,
"assignmentid"=assignmentIdj,
"sex"=sexj,
"accepttime"=acceptTimej,
"acceptday"=acceptDayj,
"day"=this.Day,
"block"=this.TrialBlock,
"trialn"=this.trialn,
"meaning"=this.meaning,
"label"=this.label,
"score"=this.score)
#print(this.data)
this.data
}
}
mturkData.list <- lapply(files, read.data.file)
mturkData <- data.frame(do.call(rbind, mturkData.list))
############################################################################################################################
######################################################## Read PHP data ########################################
############################################################################################################################
d.php.files <- list.files(d.php.data.directory,pattern="csv$",full.names = TRUE)
php.files <- d.php.files
phpData <- do.call("rbind", lapply(php.files, read.csv, header = TRUE))
#some columns not included in PHP data
phpData$sex <- NA
phpData$accepttime <- NA
phpData$acceptday <- NA
#some have dofferent names
phpData <- rename(phpData,c("hitId"="hitid",
"assignmentId"="assignmentid",
"trialType"="block",
"trialImage"="meaning"))
#need to generate label column depending on which trial type it is
phpData$label <- ifelse(phpData$block=="SentenceTest1" | phpData$block=="InteractionDirect",as.character(phpData$targetResponse),as.character(phpData$trialText))
#and generate trial numbers from the timestamp
phpData$trialn <- ave(phpData$time, phpData$workerId, phpData$day, FUN=rank)
############################################################################################################################
######################################################## Stick them together ########################################
############################################################################################################################
allData <- rbind(mturkData,phpData[colnames(mturkData)])
############################################################################################################################
############################################## Data munging: identify word order ###############################
############################################################################################################################
#constructs a dictionary for worker id based on data
construct.participant.dictionary <- function(id,data) {
#print(id)
this.p.data <- subset(data,grepl("NounTrain",block) & workerId==id)
this.p.meanings <- unique(this.p.data$meaning)
#print(paste(id,this.p.meanings))
this.p.vocab <- as.character(unlist(lapply(this.p.meanings, function(m) {unique(subset(this.p.data,meaning==m)$label)})))
this.p.dictionary <- data.frame("workerId"=id,
"meaning"=this.p.meanings,
"noun"=this.p.vocab)
this.p.dictionary
}
dictionary.list <- lapply(levels(allData$workerId), function(w) construct.participant.dictionary(w,allData))
dictionary <- do.call(rbind, dictionary.list)
#identify condition (ks or mf stimuli) by counting number of dictionary entries
conditions.list <- lapply(levels(allData$workerId), function(w) data.frame('workerId'=w,'nNouns'=nrow(subset(dictionary,workerId==w))))
conditions.df <- do.call(rbind, conditions.list)
conditions.df$condition <- as.factor(ifelse(conditions.df$nNouns==10,'ks','mf')) #give them a nicer factor name
#display this table for a quick visual inspection
conditions.df
allData <- merge(allData,conditions.df,by=c('workerId'))
#required due to sample's crazy behaviour
resample <- function(x, ...) x[sample.int(length(x), ...)]
find.closest.word<- function(w) {
dists <- adist(w,all.vocab)
min.dist.indexes = (which(dists == min(dists)))
min.dist.index <- resample(min.dist.indexes,1) #take a random one in event of ties
all.vocab[min.dist.index]
}
is.verb <- function(w,id) {
w %in% verbs
}
word.order <- function(block,id,meaning,label) {
if (length(as.character(label))==0) {NA}
else if (grepl("SentenceTrain",block) | grepl("SentenceTest",block) | grepl("SentenceComprehension",block) | grepl("InteractionDirect",block) | grepl("InteractionMatch",block)) {
order = ''
#meaning is _-split string
meaning.split <- unlist(strsplit(as.character(meaning),"_"))
agent = meaning.split[1]
patient = meaning.split[3]
verb = meaning.split[2]
#identify appropriate vocab
agent_noun = subset(dictionary,workerId==id & meaning==agent)$noun
patient_noun = subset(dictionary,workerId==id & meaning==patient)$noun
#now deal with the actual label
label.split <- unlist(strsplit(as.character(label)," "))
closest.words <- unlist(lapply(label.split,function(w) find.closest.word(w))) #should use lev distance for this
for (w in closest.words) {
if (w == agent_noun) {
order=paste(order,'A',sep='')
}
else if (w == patient_noun) {
order=paste(order,'P',sep='')
}
else if (w %in% verbs) {
order=paste(order,'V',sep='')
}
else if (w == paste(agent_noun,'ka',sep='')) {
order=paste(order,'Ap',sep='')
}
else if (w == paste(patient_noun,'ka',sep='')) {
order=paste(order,'Pp',sep='')
}
else {
order=paste(order,'?',sep='')
}}
order}
else {NA}
}
allData$wordorder <- mapply(function(block,id,meaning,label) word.order(block,id,meaning,label),allData$block,allData$workerId,allData$meaning,allData$label)
calculate.animacy <- function(block,meaning) {
if (grepl("SentenceTrain",block) | grepl("SentenceTest",block) | grepl("SentenceComprehension",block) | grepl("InteractionDirect",block) | grepl("InteractionMatch",block)) {
#meaning is _-split string
meaning.split <- unlist(strsplit(as.character(meaning),"_"))
patient = meaning.split[3]
ifelse(patient %in% inanimates,FALSE,TRUE)
}
else {NA}
}
#word.to.extract is agent, verb or patient
extract.word <- function(block,meaning,word.to.extract) {
if (grepl("SentenceTrain",block) | grepl("SentenceTest",block) | grepl("SentenceComprehension",block)) {
#meaning is _-split string
meaning.split <- unlist(strsplit(as.character(meaning),"_"))
if (word.to.extract=="agent") {
w = meaning.split[1]}
else if (word.to.extract=="verb") {
w = meaning.split[2]}
else if (word.to.extract=="patient") {
w = meaning.split[3]}
else {NA}
w
}
else {NA}
}
allData$patient.is.animate <- mapply(function(block,meaning) calculate.animacy(block,meaning),allData$block,allData$meaning)
allData$grammatical <- mapply(function(order) ifelse(order=="APV" | order=="PAV" | order=="APpV" | order=="PpAV",TRUE,FALSE),allData$wordorder)
allData$casemarked <- mapply(function(order) ifelse(grepl("p",order),TRUE,FALSE),allData$wordorder)
allData$simplewordorder <- mapply(function(order) ifelse(order=="APV" | order=="APpV","SOV",ifelse(order=="PAV" | order=="PpAV","OSV",NA)),allData$wordorder)
#couple of basic sanity checks on the training data
count(subset(allData,(block=="SentenceTrain1" | block=="SentenceComprehension1")),c("workerId","day","casemarked"))
count(subset(allData,(block=="SentenceTrain1" | block=="SentenceComprehension1")),c("casemarked","simplewordorder","patient.is.animate"))
count(subset(allData,(block=="SentenceTest1")),c("workerId","patient.is.animate","casemarked"))
write.csv(allData,"evccExpCDDataRawAll.csv")
#Create annonymised version for sharing
allDataAnon<-allData
#annonymise worker IDs
allDataAnon$workerId <- mapvalues(allDataAnon$workerId,from=levels(allDataAnon$workerId),to=paste('CD',1:length(levels(allDataAnon$workerId)),sep=''))
#remove HIT ID and assignment ID
allDataAnon$hitid <- NULL
allDataAnon$assignmentid <- NULL
#sort by id, day and trial number
allDataAnon <- allDataAnon[order(allDataAnon$workerId,allDataAnon$day,allDataAnon$trialn),]
write.csv(allDataAnon,"~/k/JennyCulbertson/EvocaseCartoon/AbstractsTalksPapers/JML/Paper/RawData/evccCDRawData.csv",row.names=FALSE)
write.csv(allDataAnon,"~/k/JennyCulbertson/_JML/Paper/RawData/evccCDRawData.csv",row.names=FALSE)
#got this from https://stackoverflow.com/questions/12840294/counting-unique-distinct-values-by-group-in-a-data-frame
exp2.counts.table <- ddply(exp2Data,~day,summarise,N=length(unique(workerId)))
#some have dofferent names
phpData <- plyr::rename(phpData,c("hitId"="hitid",
"assignmentId"="assignmentid",
"trialType"="block",
"trialImage"="meaning"))
#need to generate label column depending on which trial type it is
phpData$label <- ifelse(phpData$block=="SentenceTest1" | phpData$block=="InteractionDirect",as.character(phpData$targetResponse),as.character(phpData$trialText))
#and generate trial numbers from the timestamp
phpData$trialn <- ave(phpData$time, phpData$workerId, phpData$day, FUN=rank)
allData <- rbind(mturkData,phpData[colnames(mturkData)])
#constructs a dictionary for worker id based on data
construct.participant.dictionary <- function(id,data) {
#print(id)
this.p.data <- subset(data,grepl("NounTrain",block) & workerId==id)
this.p.meanings <- unique(this.p.data$meaning)
#print(paste(id,this.p.meanings))
this.p.vocab <- as.character(unlist(lapply(this.p.meanings, function(m) {unique(subset(this.p.data,meaning==m)$label)})))
this.p.dictionary <- data.frame("workerId"=id,
"meaning"=this.p.meanings,
"noun"=this.p.vocab)
this.p.dictionary
}
dictionary.list <- lapply(levels(allData$workerId), function(w) construct.participant.dictionary(w,allData))
dictionary <- do.call(rbind, dictionary.list)
#identify condition (ks or mf stimuli) by counting number of dictionary entries
conditions.list <- lapply(levels(allData$workerId), function(w) data.frame('workerId'=w,'nNouns'=nrow(subset(dictionary,workerId==w))))
conditions.df <- do.call(rbind, conditions.list)
conditions.df$condition <- as.factor(ifelse(conditions.df$nNouns==10,'ks','mf')) #give them a nicer factor name
#display this table for a quick visual inspection
conditions.df
allData <- merge(allData,conditions.df,by=c('workerId'))
#required due to sample's crazy behaviour
resample <- function(x, ...) x[sample.int(length(x), ...)]
find.closest.word<- function(w) {
dists <- adist(w,all.vocab)
min.dist.indexes = (which(dists == min(dists)))
min.dist.index <- resample(min.dist.indexes,1) #take a random one in event of ties
all.vocab[min.dist.index]
}
is.verb <- function(w,id) {
w %in% verbs
}
word.order <- function(block,id,meaning,label) {
if (length(as.character(label))==0) {NA}
else if (grepl("SentenceTrain",block) | grepl("SentenceTest",block) | grepl("SentenceComprehension",block) | grepl("InteractionDirect",block) | grepl("InteractionMatch",block)) {
order = ''
#meaning is _-split string
meaning.split <- unlist(strsplit(as.character(meaning),"_"))
agent = meaning.split[1]
patient = meaning.split[3]
verb = meaning.split[2]
#identify appropriate vocab
agent_noun = subset(dictionary,workerId==id & meaning==agent)$noun
patient_noun = subset(dictionary,workerId==id & meaning==patient)$noun
#now deal with the actual label
label.split <- unlist(strsplit(as.character(label)," "))
closest.words <- unlist(lapply(label.split,function(w) find.closest.word(w))) #should use lev distance for this
for (w in closest.words) {
if (w == agent_noun) {
order=paste(order,'A',sep='')
}
else if (w == patient_noun) {
order=paste(order,'P',sep='')
}
else if (w %in% verbs) {
order=paste(order,'V',sep='')
}
else if (w == paste(agent_noun,'ka',sep='')) {
order=paste(order,'Ap',sep='')
}
else if (w == paste(patient_noun,'ka',sep='')) {
order=paste(order,'Pp',sep='')
}
else {
order=paste(order,'?',sep='')
}}
order}
else {NA}
}
allData$wordorder <- mapply(function(block,id,meaning,label) word.order(block,id,meaning,label),allData$block,allData$workerId,allData$meaning,allData$label)
calculate.animacy <- function(block,meaning) {
if (grepl("SentenceTrain",block) | grepl("SentenceTest",block) | grepl("SentenceComprehension",block) | grepl("InteractionDirect",block) | grepl("InteractionMatch",block)) {
#meaning is _-split string
meaning.split <- unlist(strsplit(as.character(meaning),"_"))
patient = meaning.split[3]
ifelse(patient %in% inanimates,FALSE,TRUE)
}
else {NA}
}
#word.to.extract is agent, verb or patient
extract.word <- function(block,meaning,word.to.extract) {
if (grepl("SentenceTrain",block) | grepl("SentenceTest",block) | grepl("SentenceComprehension",block)) {
#meaning is _-split string
meaning.split <- unlist(strsplit(as.character(meaning),"_"))
if (word.to.extract=="agent") {
w = meaning.split[1]}
else if (word.to.extract=="verb") {
w = meaning.split[2]}
else if (word.to.extract=="patient") {
w = meaning.split[3]}
else {NA}
w
}
else {NA}
}
allData$patient.is.animate <- mapply(function(block,meaning) calculate.animacy(block,meaning),allData$block,allData$meaning)
allData$grammatical <- mapply(function(order) ifelse(order=="APV" | order=="PAV" | order=="APpV" | order=="PpAV",TRUE,FALSE),allData$wordorder)
allData$casemarked <- mapply(function(order) ifelse(grepl("p",order),TRUE,FALSE),allData$wordorder)
allData$simplewordorder <- mapply(function(order) ifelse(order=="APV" | order=="APpV","SOV",ifelse(order=="PAV" | order=="PpAV","OSV",NA)),allData$wordorder)
#couple of basic sanity checks on the training data
count(subset(allData,(block=="SentenceTrain1" | block=="SentenceComprehension1")),c("workerId","day","casemarked"))
count(subset(allData,(block=="SentenceTrain1" | block=="SentenceComprehension1")),c("casemarked","simplewordorder","patient.is.animate"))
count(subset(allData,(block=="SentenceTest1")),c("workerId","patient.is.animate","casemarked"))
write.csv(allData,"evccExpCDDataRawAll.csv")
#Create annonymised version for sharing
allDataAnon<-allData
#annonymise worker IDs
allDataAnon$workerId <- mapvalues(allDataAnon$workerId,from=levels(allDataAnon$workerId),to=paste('CD',1:length(levels(allDataAnon$workerId)),sep=''))
#remove HIT ID and assignment ID
allDataAnon$hitid <- NULL
allDataAnon$assignmentid <- NULL
#sort by id, day and trial number
allDataAnon <- allDataAnon[order(allDataAnon$workerId,allDataAnon$day,allDataAnon$trialn),]
write.csv(allDataAnon,"~/k/JennyCulbertson/EvocaseCartoon/AbstractsTalksPapers/JML/Paper/RawData/evccCDRawData.csv",row.names=FALSE)
write.csv(allDataAnon,"~/k/JennyCulbertson/_JML/Paper/RawData/evccCDRawData.csv",row.names=FALSE)
knitr::opts_chunk$set(echo = TRUE)
library(ggplot2)
library(plyr)
library(dplyr)
library(lme4)
library(gridExtra) #for the by-participant bar plots
#library(kableExtra)
library(broom) #for formatting lmer summary tables
#load utility functions
source('../Utilities.R')
#define colours - don't think Jenny likes these, but easy to change!
#First one is neutral, e.g. for totals
my.colours <- c("#808080","#EA7D00","#006DE9")
exp2Data <- read.csv('../RawData/evccCDRawData.csv')
#relabel for consistency with exp 1
exp2Data$AgentsCanBePatients <- ifelse(exp2Data$condition=='ks','Agents Can Be Patients','Agents Cannot Be Patients')
#it will be useful to have AgentsCannotBePatients as baseline
exp2Data$AgentsCanBePatients <- relevel(as.factor(exp2Data$AgentsCanBePatients),ref='Agents Cannot Be Patients')
#binary coding of word order
exp2Data$isSOV <- ifelse(exp2Data$simplewordorder=='SOV',1,0)
#day needs to be a factor for the stats
exp2Data$day <- as.factor(exp2Data$day)
#animacy needs to be a factor - TODO does this actually need to be renamed?
exp2Data$patient.is.animate <- factor(exp2Data$patient.is.animate)
#got this from https://stackoverflow.com/questions/12840294/counting-unique-distinct-values-by-group-in-a-data-frame
exp2.counts.table <- ddply(exp2Data,~day,summarise,N=length(unique(workerId)))
exp2.counts.table
exp2.scores.by.block <- aggregate(score~workerId+day+block,data=exp2Data,FUN=mean)
exp2.failed.noun.comprehension <- subset(exp2.scores.by.block,block=='NounComprehension2' & score<0.7)
exp2.failed.sentence.comprehension <- subset(exp2.scores.by.block,block=='SentenceComprehension1' & score<0.7)
ddply(exp2.failed.sentence.comprehension,~day,summarise,N_excluded=length(unique(workerId)))
aggregate(grammatical~day,FUN=mean,data=subset(exp2Data,block=="SentenceTest1"))
rejection.counts <- ddply(subset(exp2Data,block=="SentenceTest1" & grammatical==0),~wordorder,summarise,N=length(unique(workerId)))
#ordered list of rejection types
rejection.counts <- rejection.counts[order(-rejection.counts$N),]
rejection.counts
#since there is some data munging here, will set this up as a seperate data frame
exp2InteractionSuccessData <- droplevels(subset(exp2Data,((block=="InteractionDirect" & grammatical) | (block=="InteractionMatch")) & day==4))
exp2.interaction.success.summary <- aggregate(score~block+patient.is.animate+AgentsCanBePatients+casemarked+workerId,data=exp2InteractionSuccessData,FUN=mean)
exp2.interaction.success.summary$casemarked <- revalue(as.factor(exp2.interaction.success.summary$casemarked),
c("FALSE"="Patient not casemarked",
"TRUE"="Patient casemarked"))
exp2.interaction.success.summary$block <- plyr::revalue(exp2.interaction.success.summary$block,
c("InteractionDirect"="Participant Directs,\nSmeeble Matches",
"InteractionMatch"="Smeeble Directs,\nParticipant Matches"))
#a plot with:
#bars and 95% CIs for mean case marking by animacy
#dotplot for by-participant means
#additional point and 95% CI for casemarking collapsing over animacy
ggplot(data=exp2.interaction.success.summary, aes(x=block, y=score, fill=patient.is.animate)) +
facet_grid(AgentsCanBePatients~casemarked) +
#bars and CIs for casemarking by animacy
stat_summary(geom='bar', fun.y='mean', position=position_dodge(0.9)) +
stat_summary(geom='errorbar', fun.data='mean_cl_boot',fun.ymin="min", fun.ymax="max",width=0.3,position=position_dodge(0.9),color='black') +
#horizontal line showing chance
geom_hline(yintercept=0.5,linetype=3) +
#by-participant data
geom_dotplot(aes(x=block, y=score, shape=patient.is.animate),binaxis = "y", stackdir = "center",alpha=0.2,dotsize=1,position=position_dodge(0.9),fill='black',binpositions='all',binwidth=1/100) +
#then various axis/legend stuff
xlab("") +
theme_bw() +
ylab("Proportion of successes") +
theme(legend.title=element_blank()) +
scale_fill_manual(values=my.colours,breaks=c("FALSE", "TRUE"),labels=c("Inanimate patient", "Animate patient")) +
ggsave("../Figures/exp2-interaction-success.pdf",width=9, height=6)
#add by-participant trial counter, setting first direct trial as 1
exp2.interaction.direct.data <- subset(exp2RecallVsInteractionData,block=="InteractionDirect")
#since there is some data munging here, will set this up as a seperate data frame
exp2RecallVsInteractionData <- subset(exp2Data,(block=="InteractionDirect" | block=="SentenceTest1") & grammatical & day==4)
#want recall to be the reference level
exp2RecallVsInteractionData$block <- relevel(droplevels(exp2RecallVsInteractionData$block),ref="SentenceTest1")
exp2.recall.vs.interaction.summary <- aggregate(casemarked~patient.is.animate+block+workerId+AgentsCanBePatients,data=exp2RecallVsInteractionData,FUN=mean)
#this is aggregating over animacy
exp2.recall.vs.interaction.summary.total <- aggregate(casemarked~block+AgentsCanBePatients+workerId,data=exp2RecallVsInteractionData,FUN=mean)
#prettier names for printing
exp2.recall.vs.interaction.summary$block <- revalue(exp2.recall.vs.interaction.summary$block,
c("SentenceTest1"="Recall",
"InteractionDirect"="Interaction"))
exp2.recall.vs.interaction.summary.total$block <- revalue(exp2.recall.vs.interaction.summary.total$block,
c("SentenceTest1"="Recall",
"InteractionDirect"="Interaction"))
exp2.recall.vs.interaction.summary.total$patient.is.animate <- "All"
#add by-participant trial counter, setting first direct trial as 1
exp2.interaction.direct.data <- subset(exp2RecallVsInteractionData,block=="InteractionDirect")
exp2.interaction.direct.data$trialNumber <- plyr::ddply(exp2.interaction.direct.data, plyr::.(workerId), plyr::mutate, id = seq_along(trialn))$id
exp2.interaction.direct.data$casemarked <- as.numeric(exp2.interaction.direct.data$casemarked)
ggplot(exp2.interaction.direct.data,aes(x=trialNumber,y=casemarked,colour=patient.is.animate)) +
facet_grid(~AgentsCanBePatients) +
stat_summary(geom='line', fun.y='mean', position=position_dodge(0.9)) #+
#stat_summary(geom='errorbar', fun.data='mean_cl_boot',fun.ymin="min", fun.ymax="max",width=0.3,position=position_dodge(0.9),color='black')
#try smoothing for the plot
exp2.interaction.direct.data$trialNumberBinned <- (exp2.interaction.direct.data$trialNumber-1) %/% 5
ggplot(exp2.interaction.direct.data,aes(x=trialNumberBinned,y=casemarked,colour=patient.is.animate)) +
facet_grid(~AgentsCanBePatients) +
stat_summary(geom='line', fun.y='mean') +
stat_summary(geom='errorbar', fun.data='mean_cl_boot',fun.ymin="min", fun.ymax="max",width=0.3) +
scale_x_continuous(breaks=0:7,labels=c("1-5","6-10","11-15","16-20","21-25","26-30","30-35","36-40"))
ggplot(exp2.interaction.direct.data,aes(x=trialNumber,y=casemarked,colour=patient.is.animate)) +
facet_grid(~AgentsCanBePatients) +
stat_summary(geom='line', fun.y='mean') +
scale_colour_manual(values=my.colours,breaks=c("FALSE", "TRUE"),labels=c("Inanimate patient", "Animate patient"))
#try smoothing for the plot
exp2.interaction.direct.data$trialNumberBinned <- (exp2.interaction.direct.data$trialNumber-1) %/% 5
ggplot(exp2.interaction.direct.data,aes(x=trialNumberBinned,y=casemarked,colour=patient.is.animate)) +
facet_grid(~AgentsCanBePatients) +
stat_summary(geom='line', fun.y='mean') +
stat_summary(geom='errorbar', fun.data='mean_cl_boot',fun.ymin="min", fun.ymax="max",width=0.3) +
scale_x_continuous(breaks=0:7,labels=c("1-5","6-10","11-15","16-20","21-25","26-30","30-35","36-40"))+
scale_colour_manual(values=my.colours,breaks=c("FALSE", "TRUE"),labels=c("Inanimate patient", "Animate patient"))
knitr::opts_chunk$set(echo = TRUE)
options(width = 300)
library(ggplot2)
library(plyr)
library(dplyr)
library(lme4)
#load utility functions
source('../_Utilities.R')
#define colours - don't think Jenny likes these, but easy to change!
#First one is neutral, e.g. for totals
my.colours <- c("#808080","#EA7D00","#006DE9")
exp2Data <- read.csv('../RawData/exp2Data.csv')
#at some point we switched terminology in the paper from Agents Can/Cannot be Patients to Subjects Can/Cannot Be Objects - need to correct this throughout
exp2Data$EventType <- revalue(exp2Data$EventType,
c("Agents Cannot Be Patients"="Subjects Cannot Be Objects",
"Agents Can Be Patients"="Subjects Can Be Objects"))
#it will be useful to have Subjects Cannot Be Objects as baseline
exp2Data$EventType <- relevel(as.factor(exp2Data$EventType),ref='Subjects Cannot Be Objects')
#day needs to be a factor for the stats
exp2Data$Day <- as.factor(exp2Data$Day)
#got this from https://stackoverflow.com/questions/12840294/counting-unique-distinct-values-by-group-in-a-data-frame
exp2.counts.table <- plyr::ddply(exp2Data,~Day,summarise,N=length(unique(workerId)))
exp2.counts.table
exp2.scores.by.block <- aggregate(score~workerId+Day+Block,data=exp2Data,FUN=mean)
exp2.failed.noun.comprehension <- subset(exp2.scores.by.block,Block=='NounComprehension2' & score<0.7)
exp2.failed.sentence.comprehension <- subset(exp2.scores.by.block,Block=='SentenceComprehension1' & score<0.7)
ddply(exp2.failed.sentence.comprehension,~Day,summarise,N_excluded=length(unique(workerId)))
aggregate(grammatical~Day,FUN=mean,data=subset(exp2Data,Block=="SentenceTest1"))
rejection.counts <- ddply(subset(exp2Data,Block=="SentenceTest1" & grammatical==0),~wordorder,summarise,N=length(unique(workerId)))
#ordered list of rejection types
rejection.counts <- rejection.counts[order(-rejection.counts$N),]
rejection.counts
exp2.score.summary <- aggregate(score~casemarked+Animacy+Day+EventType+workerId,data=subset(exp2Data,Block=="SentenceComprehension1"),FUN=mean)
exp2.score.summary$casemarked <- revalue(as.factor(exp2.score.summary$casemarked),
c("FALSE"="Patient not casemarked",
"TRUE"="Patient casemarked"))
#for the dotplot, there are too many participants at ceiling to show the dots - instead I am going
#to withhold those dots and add a numerical annotation
exp2.score.summary$IsPerfect <- ifelse(exp2.score.summary$score==1,1,0)
exp2.score.perfect.ns <- data.frame(summarize(group_by(subset(exp2.score.summary,IsPerfect==1),Day,Animacy,casemarked,EventType,.drop = FALSE),n()))
exp2.score.perfect.ns <- plyr::rename(exp2.score.perfect.ns,c("n.."="count"))
ggplot(data=exp2.score.summary, aes(x=Day, y=score, fill=Animacy,colour=Animacy)) +
#facet by condition and marking
facet_grid(EventType~casemarked) +
#points and CIs for score by animacy
stat_summary(geom='errorbar', fun.data='mean_cl_boot',fun.ymin="min", fun.ymax="max",
width=0.3,position=position_dodge(0.9),colour='black') +
stat_summary(geom='point', fun.y='mean', position=position_dodge(0.9),size=3) +
stat_summary(geom='point', fun.y='mean', position=position_dodge(0.9),size=3,shape=1,colour='black') +
#horizontal line showing chance
geom_hline(yintercept=0.5,linetype=3) +
#by-participant data
geom_dotplot(data=subset(exp2.score.summary,IsPerfect==0),
aes(x=Day, y=score, shape=Animacy),binaxis = "y",
stackdir = "centerwhole",stackratio=1,alpha=0.5,dotsize=1,
position=position_dodge(0.9),binpositions='all',binwidth=1/100) +
geom_text(data=exp2.score.perfect.ns,aes(x=Day,y=1.05,label=count),position=position_dodge(0.9),size=3,colour='black') +
#force all points to be circles, and exclude from legend
scale_shape_manual(values=c(19,19),guide=FALSE)+
#then various axis/legend stuff
xlab("Day") +
theme_bw() +
#ylab("Proportion correct responses") +
scale_y_continuous(name="Proportion correct responses",breaks=seq(0,1,0.25)) +
theme(legend.title=element_blank(),legend.position="top") +
scale_fill_manual(values=my.colours[2:3],breaks=c("FALSE", "TRUE"),labels=c("Inanimate patient", "Animate patient")) +
scale_colour_manual(values=my.colours[2:3],breaks=c("FALSE", "TRUE"),labels=c("Inanimate patient", "Animate patient")) +
ggsave("../Figures/exp2-identification-accuracy.pdf",width=9, height=9)
